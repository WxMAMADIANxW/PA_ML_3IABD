{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dadac0d",
   "metadata": {},
   "source": [
    "Recuperation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79757f",
   "metadata": {},
   "source": [
    "Processing des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b088c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637764c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./dataset\"\n",
    "os.chdir(dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439880a4",
   "metadata": {},
   "source": [
    "Stockage des images dans X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5974e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(path,img_size):\n",
    "    list_X,list_Y = [],[]\n",
    "    for filename in tqdm(os.listdir(path)):\n",
    "        img = ImageOps.grayscale(Image.open(path+\"/\"+filename).resize(img_size))\n",
    "        array = np.asarray(img).flatten().tolist()\n",
    "        \n",
    "        list_X.append(array)\n",
    "    \n",
    "        if \"Dataset_Mangas\" in path:\n",
    "            class_array = 0\n",
    "        elif \"Dataset_Romans\" in path:\n",
    "            class_array = 1\n",
    "        elif \"Dataset_Comics\" in path:\n",
    "            class_array = 2\n",
    "        \n",
    "        list_Y.append(class_array)\n",
    "        \n",
    "      \n",
    "    X ,Y = np.array(list_X), np.array(list_Y)\n",
    "    return X/255.,Y.reshape((Y.shape[0],))/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128bd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2034/2034 [01:39<00:00, 20.51it/s]\n"
     ]
    }
   ],
   "source": [
    "X_mangas,Y_mangas = preprocess_dataset(\"C:/Users/Mamadian/Documents/ESGI/MachineLearning/PA_ML_3IABD/dataset/Dataset_Mangas/\",(56,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6521206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2089/2089 [03:59<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "X_comics,Y_comics = preprocess_dataset(\"C:/Users/Mamadian/Documents/ESGI/MachineLearning/PA_ML_3IABD/dataset/Dataset_Comics/\",(56,56))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463c90ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2571/2571 [02:48<00:00, 15.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_romans,Y_romans = preprocess_dataset(\"C:/Users/Mamadian/Documents/ESGI/MachineLearning/PA_ML_3IABD/dataset/Dataset_Romans/\",(56,56))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599198c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007ec3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mangas_train, X_mangas_test, y_mangas_train, y_mangas_test = train_test_split(X_mangas, Y_mangas, test_size=0.33, random_state=42)\n",
    "X_romans_train, X_romans_test, y_romans_train, y_romans_test = train_test_split(X_romans, Y_romans, test_size=0.33, random_state=42)\n",
    "X_comics_train, X_comics_test, y_comics_train, y_comics_test = train_test_split(X_comics, Y_comics, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9f1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_mangas_train, X_romans_train, X_comics_train), axis=0)\n",
    "y_train = np.concatenate((y_mangas_train, y_romans_train, y_comics_train), axis=0)\n",
    "\n",
    "X_test = np.concatenate((X_mangas_test, X_romans_test, X_comics_test), axis=0)\n",
    "y_test = np.concatenate((y_mangas_test, y_romans_test, y_comics_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4164a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(75,), max_iter=1200, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, random_state=1,\n",
    "                    learning_rate_init=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12be3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255**2.\n",
    "X_test = X_test /255**2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b283f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.09089930\n",
      "Iteration 2, loss = 1.07989156\n",
      "Iteration 3, loss = 1.05687401\n",
      "Iteration 4, loss = 1.00899916\n",
      "Iteration 5, loss = 0.91953615\n",
      "Iteration 6, loss = 0.78359667\n",
      "Iteration 7, loss = 0.64525614\n",
      "Iteration 8, loss = 0.53813824\n",
      "Iteration 9, loss = 0.46403281\n",
      "Iteration 10, loss = 0.40934106\n",
      "Iteration 11, loss = 0.36346638\n",
      "Iteration 12, loss = 0.32748728\n",
      "Iteration 13, loss = 0.30063885\n",
      "Iteration 14, loss = 0.28579121\n",
      "Iteration 15, loss = 0.26316655\n",
      "Iteration 16, loss = 0.24774084\n",
      "Iteration 17, loss = 0.23867701\n",
      "Iteration 18, loss = 0.22258848\n",
      "Iteration 19, loss = 0.21775763\n",
      "Iteration 20, loss = 0.20785897\n",
      "Iteration 21, loss = 0.20016645\n",
      "Iteration 22, loss = 0.19248569\n",
      "Iteration 23, loss = 0.18597279\n",
      "Iteration 24, loss = 0.18390564\n",
      "Iteration 25, loss = 0.17821204\n",
      "Iteration 26, loss = 0.17601567\n",
      "Iteration 27, loss = 0.17044494\n",
      "Iteration 28, loss = 0.16707474\n",
      "Iteration 29, loss = 0.16218128\n",
      "Iteration 30, loss = 0.16023988\n",
      "Iteration 31, loss = 0.15797825\n",
      "Iteration 32, loss = 0.15606007\n",
      "Iteration 33, loss = 0.15046585\n",
      "Iteration 34, loss = 0.15197826\n",
      "Iteration 35, loss = 0.14833518\n",
      "Iteration 36, loss = 0.14377631\n",
      "Iteration 37, loss = 0.14292132\n",
      "Iteration 38, loss = 0.14175631\n",
      "Iteration 39, loss = 0.13782580\n",
      "Iteration 40, loss = 0.13718840\n",
      "Iteration 41, loss = 0.13416868\n",
      "Iteration 42, loss = 0.13202607\n",
      "Iteration 43, loss = 0.12996305\n",
      "Iteration 44, loss = 0.12633653\n",
      "Iteration 45, loss = 0.12691347\n",
      "Iteration 46, loss = 0.12427354\n",
      "Iteration 47, loss = 0.12375267\n",
      "Iteration 48, loss = 0.12057223\n",
      "Iteration 49, loss = 0.11956788\n",
      "Iteration 50, loss = 0.11764460\n",
      "Iteration 51, loss = 0.11656793\n",
      "Iteration 52, loss = 0.11335518\n",
      "Iteration 53, loss = 0.11267308\n",
      "Iteration 54, loss = 0.11145919\n",
      "Iteration 55, loss = 0.11046800\n",
      "Iteration 56, loss = 0.10947133\n",
      "Iteration 57, loss = 0.10668427\n",
      "Iteration 58, loss = 0.10492857\n",
      "Iteration 59, loss = 0.10260429\n",
      "Iteration 60, loss = 0.10363086\n",
      "Iteration 61, loss = 0.10173748\n",
      "Iteration 62, loss = 0.09906711\n",
      "Iteration 63, loss = 0.09836761\n",
      "Iteration 64, loss = 0.09918843\n",
      "Iteration 65, loss = 0.09489528\n",
      "Iteration 66, loss = 0.09250598\n",
      "Iteration 67, loss = 0.09331194\n",
      "Iteration 68, loss = 0.09257961\n",
      "Iteration 69, loss = 0.08930521\n",
      "Iteration 70, loss = 0.08788525\n",
      "Iteration 71, loss = 0.08723345\n",
      "Iteration 72, loss = 0.08516860\n",
      "Iteration 73, loss = 0.08514346\n",
      "Iteration 74, loss = 0.08204299\n",
      "Iteration 75, loss = 0.08214405\n",
      "Iteration 76, loss = 0.08025786\n",
      "Iteration 77, loss = 0.08207691\n",
      "Iteration 78, loss = 0.07955491\n",
      "Iteration 79, loss = 0.07821242\n",
      "Iteration 80, loss = 0.07795818\n",
      "Iteration 81, loss = 0.07672351\n",
      "Iteration 82, loss = 0.07515019\n",
      "Iteration 83, loss = 0.07512513\n",
      "Iteration 84, loss = 0.07370376\n",
      "Iteration 85, loss = 0.07289524\n",
      "Iteration 86, loss = 0.07324982\n",
      "Iteration 87, loss = 0.07336984\n",
      "Iteration 88, loss = 0.07028258\n",
      "Iteration 89, loss = 0.06927064\n",
      "Iteration 90, loss = 0.07104306\n",
      "Iteration 91, loss = 0.06991590\n",
      "Iteration 92, loss = 0.06829472\n",
      "Iteration 93, loss = 0.06707912\n",
      "Iteration 94, loss = 0.06726283\n",
      "Iteration 95, loss = 0.06571750\n",
      "Iteration 96, loss = 0.06694779\n",
      "Iteration 97, loss = 0.06652645\n",
      "Iteration 98, loss = 0.06443891\n",
      "Iteration 99, loss = 0.06310696\n",
      "Iteration 100, loss = 0.06337431\n",
      "Iteration 101, loss = 0.06344930\n",
      "Iteration 102, loss = 0.06258466\n",
      "Iteration 103, loss = 0.06123248\n",
      "Iteration 104, loss = 0.06084238\n",
      "Iteration 105, loss = 0.06006813\n",
      "Iteration 106, loss = 0.06172459\n",
      "Iteration 107, loss = 0.06044808\n",
      "Iteration 108, loss = 0.05998675\n",
      "Iteration 109, loss = 0.06056112\n",
      "Iteration 110, loss = 0.05974707\n",
      "Iteration 111, loss = 0.05818216\n",
      "Iteration 112, loss = 0.05984002\n",
      "Iteration 113, loss = 0.05918541\n",
      "Iteration 114, loss = 0.05758600\n",
      "Iteration 115, loss = 0.05663566\n",
      "Iteration 116, loss = 0.05655908\n",
      "Iteration 117, loss = 0.05644376\n",
      "Iteration 118, loss = 0.05683471\n",
      "Iteration 119, loss = 0.05639517\n",
      "Iteration 120, loss = 0.05655489\n",
      "Iteration 121, loss = 0.05459637\n",
      "Iteration 122, loss = 0.05506865\n",
      "Iteration 123, loss = 0.05445111\n",
      "Iteration 124, loss = 0.05399966\n",
      "Iteration 125, loss = 0.05313721\n",
      "Iteration 126, loss = 0.05351751\n",
      "Iteration 127, loss = 0.05361863\n",
      "Iteration 128, loss = 0.05426726\n",
      "Iteration 129, loss = 0.05327076\n",
      "Iteration 130, loss = 0.05174891\n",
      "Iteration 131, loss = 0.05218166\n",
      "Iteration 132, loss = 0.05346738\n",
      "Iteration 133, loss = 0.05275611\n",
      "Iteration 134, loss = 0.05301511\n",
      "Iteration 135, loss = 0.05286892\n",
      "Iteration 136, loss = 0.05165850\n",
      "Iteration 137, loss = 0.05004323\n",
      "Iteration 138, loss = 0.05081564\n",
      "Iteration 139, loss = 0.05064793\n",
      "Iteration 140, loss = 0.05114888\n",
      "Iteration 141, loss = 0.05030084\n",
      "Iteration 142, loss = 0.04965121\n",
      "Iteration 143, loss = 0.05008643\n",
      "Iteration 144, loss = 0.05010473\n",
      "Iteration 145, loss = 0.04958721\n",
      "Iteration 146, loss = 0.04955502\n",
      "Iteration 147, loss = 0.04863825\n",
      "Iteration 148, loss = 0.04875493\n",
      "Iteration 149, loss = 0.04810889\n",
      "Iteration 150, loss = 0.04743134\n",
      "Iteration 151, loss = 0.04937973\n",
      "Iteration 152, loss = 0.04947801\n",
      "Iteration 153, loss = 0.04688205\n",
      "Iteration 154, loss = 0.04766534\n",
      "Iteration 155, loss = 0.04790529\n",
      "Iteration 156, loss = 0.04850265\n",
      "Iteration 157, loss = 0.04765371\n",
      "Iteration 158, loss = 0.04664216\n",
      "Iteration 159, loss = 0.04580255\n",
      "Iteration 160, loss = 0.04589831\n",
      "Iteration 161, loss = 0.04627324\n",
      "Iteration 162, loss = 0.04624768\n",
      "Iteration 163, loss = 0.04618926\n",
      "Iteration 164, loss = 0.04670922\n",
      "Iteration 165, loss = 0.04778316\n",
      "Iteration 166, loss = 0.04511876\n",
      "Iteration 167, loss = 0.04478882\n",
      "Iteration 168, loss = 0.04493239\n",
      "Iteration 169, loss = 0.04418561\n",
      "Iteration 170, loss = 0.04574120\n",
      "Iteration 171, loss = 0.04479392\n",
      "Iteration 172, loss = 0.04483614\n",
      "Iteration 173, loss = 0.04547172\n",
      "Iteration 174, loss = 0.04334938\n",
      "Iteration 175, loss = 0.04504711\n",
      "Iteration 176, loss = 0.04413056\n",
      "Iteration 177, loss = 0.04560024\n",
      "Iteration 178, loss = 0.04382618\n",
      "Iteration 179, loss = 0.04672894\n",
      "Iteration 180, loss = 0.04477081\n",
      "Iteration 181, loss = 0.04447247\n",
      "Iteration 182, loss = 0.04426266\n",
      "Iteration 183, loss = 0.04206383\n",
      "Iteration 184, loss = 0.04473428\n",
      "Iteration 185, loss = 0.04439918\n",
      "Iteration 186, loss = 0.04274928\n",
      "Iteration 187, loss = 0.04269844\n",
      "Iteration 188, loss = 0.04449834\n",
      "Iteration 189, loss = 0.04088700\n",
      "Iteration 190, loss = 0.04192067\n",
      "Iteration 191, loss = 0.04129644\n",
      "Iteration 192, loss = 0.04104818\n",
      "Iteration 193, loss = 0.04109101\n",
      "Iteration 194, loss = 0.04091940\n",
      "Iteration 195, loss = 0.04049131\n",
      "Iteration 196, loss = 0.04087939\n",
      "Iteration 197, loss = 0.04101608\n",
      "Iteration 198, loss = 0.03998709\n",
      "Iteration 199, loss = 0.04069739\n",
      "Iteration 200, loss = 0.04035474\n",
      "Iteration 201, loss = 0.04267803\n",
      "Iteration 202, loss = 0.04047408\n",
      "Iteration 203, loss = 0.04064372\n",
      "Iteration 204, loss = 0.03998205\n",
      "Iteration 205, loss = 0.03944482\n",
      "Iteration 206, loss = 0.04019605\n",
      "Iteration 207, loss = 0.03947541\n",
      "Iteration 208, loss = 0.03882883\n",
      "Iteration 209, loss = 0.03973020\n",
      "Iteration 210, loss = 0.03976593\n",
      "Iteration 211, loss = 0.03926313\n",
      "Iteration 212, loss = 0.03834592\n",
      "Iteration 213, loss = 0.03849377\n",
      "Iteration 214, loss = 0.03821287\n",
      "Iteration 215, loss = 0.04021330\n",
      "Iteration 216, loss = 0.03776093\n",
      "Iteration 217, loss = 0.03958487\n",
      "Iteration 218, loss = 0.03910850\n",
      "Iteration 219, loss = 0.03805244\n",
      "Iteration 220, loss = 0.03766166\n",
      "Iteration 221, loss = 0.03784705\n",
      "Iteration 222, loss = 0.03796377\n",
      "Iteration 223, loss = 0.03927661\n",
      "Iteration 224, loss = 0.03702184\n",
      "Iteration 225, loss = 0.03694525\n",
      "Iteration 226, loss = 0.03827461\n",
      "Iteration 227, loss = 0.03699305\n",
      "Iteration 228, loss = 0.03866138\n",
      "Iteration 229, loss = 0.03778891\n",
      "Iteration 230, loss = 0.03734877\n",
      "Iteration 231, loss = 0.03818683\n",
      "Iteration 232, loss = 0.03685394\n",
      "Iteration 233, loss = 0.03574323\n",
      "Iteration 234, loss = 0.03690013\n",
      "Iteration 235, loss = 0.03748341\n",
      "Iteration 236, loss = 0.03688004\n",
      "Iteration 237, loss = 0.03692369\n",
      "Iteration 238, loss = 0.03616990\n",
      "Iteration 239, loss = 0.03891840\n",
      "Iteration 240, loss = 0.03688451\n",
      "Iteration 241, loss = 0.03674548\n",
      "Iteration 242, loss = 0.03658389\n",
      "Iteration 243, loss = 0.03508831\n",
      "Iteration 244, loss = 0.03522991\n",
      "Iteration 245, loss = 0.03598584\n",
      "Iteration 246, loss = 0.03629724\n",
      "Iteration 247, loss = 0.03557336\n",
      "Iteration 248, loss = 0.03524307\n",
      "Iteration 249, loss = 0.03544423\n",
      "Iteration 250, loss = 0.03501352\n",
      "Iteration 251, loss = 0.03643723\n",
      "Iteration 252, loss = 0.03626543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.03427441\n",
      "Iteration 254, loss = 0.03463268\n",
      "Iteration 255, loss = 0.03629829\n",
      "Iteration 256, loss = 0.03481174\n",
      "Iteration 257, loss = 0.03571782\n",
      "Iteration 258, loss = 0.03474690\n",
      "Iteration 259, loss = 0.03516283\n",
      "Iteration 260, loss = 0.03400654\n",
      "Iteration 261, loss = 0.03516309\n",
      "Iteration 262, loss = 0.03339108\n",
      "Iteration 263, loss = 0.03414776\n",
      "Iteration 264, loss = 0.03544421\n",
      "Iteration 265, loss = 0.03358088\n",
      "Iteration 266, loss = 0.03400207\n",
      "Iteration 267, loss = 0.03455731\n",
      "Iteration 268, loss = 0.03339214\n",
      "Iteration 269, loss = 0.03536923\n",
      "Iteration 270, loss = 0.03427813\n",
      "Iteration 271, loss = 0.03384314\n",
      "Iteration 272, loss = 0.03408404\n",
      "Iteration 273, loss = 0.03309860\n",
      "Iteration 274, loss = 0.03319445\n",
      "Iteration 275, loss = 0.03405960\n",
      "Iteration 276, loss = 0.03449149\n",
      "Iteration 277, loss = 0.03323161\n",
      "Iteration 278, loss = 0.03378838\n",
      "Iteration 279, loss = 0.03330113\n",
      "Iteration 280, loss = 0.03303468\n",
      "Iteration 281, loss = 0.03242438\n",
      "Iteration 282, loss = 0.03425969\n",
      "Iteration 283, loss = 0.03253501\n",
      "Iteration 284, loss = 0.03184779\n",
      "Iteration 285, loss = 0.03353181\n",
      "Iteration 286, loss = 0.03344614\n",
      "Iteration 287, loss = 0.03289621\n",
      "Iteration 288, loss = 0.03235635\n",
      "Iteration 289, loss = 0.03269885\n",
      "Iteration 290, loss = 0.03276777\n",
      "Iteration 291, loss = 0.03174092\n",
      "Iteration 292, loss = 0.03157951\n",
      "Iteration 293, loss = 0.03162447\n",
      "Iteration 294, loss = 0.03082343\n",
      "Iteration 295, loss = 0.03151728\n",
      "Iteration 296, loss = 0.03196682\n",
      "Iteration 297, loss = 0.03321390\n",
      "Iteration 298, loss = 0.03117121\n",
      "Iteration 299, loss = 0.03229523\n",
      "Iteration 300, loss = 0.03208914\n",
      "Iteration 301, loss = 0.03144566\n",
      "Iteration 302, loss = 0.03075570\n",
      "Iteration 303, loss = 0.03082939\n",
      "Iteration 304, loss = 0.03113923\n",
      "Iteration 305, loss = 0.03188009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(75,), learning_rate_init=0.1, max_iter=1200,\n",
       "              random_state=1, solver='sgd', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "220aa3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.991970\n",
      "Test set score: 0.985979\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1063b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf687d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test[1024].reshape((1,3136))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b26855c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a005c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f08905",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mlp,open(\"./saved_model.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1949038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"./saved_model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c0fa604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccess_image(filepath, img_size):\n",
    "    \n",
    "    img = ImageOps.grayscale(Image.open(filepath).resize(img_size))\n",
    "    array = np.asarray(img) / 255**2\n",
    "    \n",
    "    return np.array(array.flatten().tolist()).reshape((1,img_size[0]*img_size[1]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9852672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_infer(model, input_):\n",
    "    return model.predict(input_).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7122954",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_= proccess_image(\"C:/Users/Mamadian/Documents/ESGI/MachineLearning/PA_ML_3IABD/dataset/AT_WildHunt_Final-04-flat.jpg\",(56,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f022b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_infer(loaded_model,input_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
